{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIO727P - Bioinformatics Software Development Group Project (2019/20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AIM: To retrive information about human protein kinases from various databases and compile into one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version: Python 3.6.9\n",
    "\n",
    "# import the required packages\n",
    "\n",
    "# !pip3 install pandas # run this if there is an error importing pandas\n",
    "import pandas as pd # import pandas\n",
    "import re # import regular expression\n",
    "import urllib.request # import url library module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1:__ Compile a list of human protein kinases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1a:__ Use UniProt to gather a list of entry names and accession numbers for the protein kinases listed on the URL specified in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.uniprot.org/docs/pkinfam.txt\" # retrieve webpage of human kinases from UniProt\n",
    "webpage=urllib.request.urlopen(url) # open the URL\n",
    "myfile=webpage.read().decode() # read the URL contents\n",
    "\n",
    "hum_kin=re.findall(r\"([A-Z0-9]+)_HUMAN\", myfile) # create a regular expression to find all human kinases and extract all to a list\n",
    "\n",
    "uni_id=re.findall(r\"_HUMAN\\s+\\((.*?)\\)\", myfile)\n",
    "\n",
    "human_kinases=[] # open an empty list to store UniProt identifiers for all human kinases\n",
    "uniprot_id=[] # open an empty list to store UniProt accession numbers for all human kinases\n",
    "\n",
    "for h in range(len(hum_kin)):\n",
    "    human_kinases.append(hum_kin[h]+\"_HUMAN\") # append identifiers to new list, re-adding the \"_HUMAN\" found on all identifiers\n",
    "    uniprot_id.append(uni_id[h].replace(\" \", \"\")) # append accession numbers to new list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1b:__ Append a list of additional kinases found from phosphosite webscraping to existing lists using acquired UniProt entry names and accession numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_kinases=pd.read_csv(\"extra_kinases.csv\") # open the extra kinase list \n",
    "extra_entries_list=list(extra_kinases.Entry_name) # extract extra entry names as a list\n",
    "extra_accessions_list=list(extra_kinases.uniprot_id) # extract extra entry names as a list\n",
    "    \n",
    "for k in range(len(extra_accessions_list)):\n",
    "    uniprot_id.append(extra_accessions_list[k]) # append extra accession numbers to list\n",
    "    human_kinases.append(extra_entries_list[k]) # append extra identifiers to list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1c:__ Create a dataframe with the UniProt entries and accession numbers - this is the basis for the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Entry_name' : human_kinases}) # create a new table with the header entry name consisting of the human_kinases list\n",
    "df['UniProt_ID']=uniprot_id # add the uniprot id list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ Extract following kinase information from UniProt:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2a:__ Protein names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_protein_name=[] # open two empty lists for the two different types of names seen\n",
    "alternative_protein_names=[]\n",
    "\n",
    "\n",
    "for x in range(len(uniprot_id)):\n",
    "    protein_url=\"https://www.uniprot.org/uniprot/?query=id:\"+uniprot_id[x]+\"&columns=protein%20names&format=tab\" # retrieve webpage\n",
    "    protein_webpage=urllib.request.urlopen(protein_url) # open the URL\n",
    "    protein_file=protein_webpage.read().decode() # read the URL contents \n",
    "        \n",
    "    protein_list=protein_file.split(\"\\n\") # seperate protein name from header\n",
    "    \n",
    "    pattern1=re.compile(r\"\\[(Cleaved into|Includes): (.*?)\\]\") # regular expression for notes within protein names\n",
    "    prot_names1=pattern1.sub(\"\", (str(protein_list[1]))) # remove the notes from the string\n",
    "    \n",
    "    pattern2=re.compile(r\"\\(EC(.*?)\\)\") # regular expression for EC numbers\n",
    "    prot_names2=pattern2.sub(\"\", prot_names1) # remove EC numbers from the string\n",
    "    \n",
    "    # certain names have brackets within their names, and to avoid getting recognised by the regular expression, they need\n",
    "    # to be replaced by curly brackets\n",
    "    pattern3=re.compile(r\"\\((.*?)\\)]\") \n",
    "    prot_names3=pattern3.sub(\"{acetyl-transferring}]\", prot_names2)\n",
    "    \n",
    "    pattern4=re.compile(r\"\\(A\\)\")\n",
    "    prot_names4=pattern4.sub(\"{A}\", prot_names3)\n",
    "    \n",
    "    pattern5=re.compile(r\"\\(C\\)\")\n",
    "    prot_names5=pattern5.sub(\"{C}\", prot_names4)\n",
    "    \n",
    "    pattern6=re.compile(r\"\\(II\\)\")\n",
    "    prot_names6=pattern6.sub(\"{II}\", prot_names5)\n",
    "    \n",
    "    pattern7=re.compile(r\"\\(v-fgr\\)\")\n",
    "    prot_names7=pattern7.sub(\"{v-fgr}\", prot_names6)\n",
    "    \n",
    "    # exclude all the alternative names that are contained within regular brackets\n",
    "    pattern8=re.compile(r\"\\((.*?)\\)\")\n",
    "    prot_names8=pattern8.sub(\"\", prot_names7)\n",
    "    \n",
    "    prot_names9=prot_names8.replace(\"{\", \"(\").replace(\"}\", \")\").replace(\"' \", \"\") # replace punctuation in the string\n",
    "\n",
    "    primary_protein_name.append(prot_names9) # append primary protein names to list\n",
    "    \n",
    "    matches=re.findall(r\"\\((.*?)\\)\", prot_names7) # find all alternate protein names contained within brackets \n",
    "    alt_prot_names=(str(matches)).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace(\"{\", \"(\").replace(\"}\", \")\")\n",
    "        # replace punctuation in the string \n",
    "    alternative_protein_names.append(alt_prot_names) # append alternative protein names to list\n",
    "\n",
    "df['Primary_Protein_Name']=primary_protein_name # add the primary names list as a column to the dataframe\n",
    "df['Alternative_Protein_Name(s)']=alternative_protein_names # add the alternate names list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2b:__ Gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primary gene symbol\n",
    "\n",
    "primary_gene_name=[] # open empty list for primary gene names\n",
    "\n",
    "for p in range(len(uniprot_id)):\n",
    "    gene_url=\"https://www.uniprot.org/uniprot/?query=id:\"+uniprot_id[p]+\"&columns=genes(PREFERRED)&format=tab\" # retrieve webpage\n",
    "    gene_webpage=urllib.request.urlopen(gene_url) # open the URL\n",
    "    gene_file=gene_webpage.read().decode() # read the URL contents \n",
    "    \n",
    "    gene_list=gene_file.split(\"\\n\") # seperate gene name from header\n",
    "    \n",
    "    primary_gene_name.append(str(gene_list[1])) # append gene name to the new list\n",
    "\n",
    "# alternate gene symbol(s)\n",
    "\n",
    "alternative_gene_names=[] # open new list for alternative gene names\n",
    "\n",
    "for a in range(len(uniprot_id)):\n",
    "    gene_alt_url=\"https://www.uniprot.org/uniprot/?query=id:\"+uniprot_id[a]+\"&columns=genes(ALTERNATIVE)&format=tab\" # retrieve webpage\n",
    "    gene_alt_webpage=urllib.request.urlopen(gene_alt_url) # open the URL\n",
    "    gene_alt_file=gene_alt_webpage.read().decode() # read the URL contents \n",
    "    \n",
    "    gene_alt_list=gene_alt_file.split(\"\\n\") # seperate gene name from header\n",
    "    \n",
    "    gene_alt_names1=(str(gene_alt_list[1])).split(\" \") # split by space\n",
    "    gene_alt_names2=(str(gene_alt_names1)).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n",
    "    alternative_gene_names.append(gene_alt_names2) # append gene names to the new list\n",
    "\n",
    "df['Gene_Symbol']=primary_gene_name # add the primary names list as a column to the dataframe\n",
    "df['Alternative_Gene_Name(s)']=alternative_gene_names # add the alternate names list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2c:__ Families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "family=[] # open new list for family names \n",
    "\n",
    "for f in range(len(uniprot_id)):\n",
    "    fam_url=\"https://www.uniprot.org/uniprot/?query=id:\"+uniprot_id[f]+\"&columns=families&format=tab\" # retrieve webpage\n",
    "    fam_webpage=urllib.request.urlopen(fam_url) # open the URL\n",
    "    fam_file=fam_webpage.read().decode() # read the URL contents \n",
    "    \n",
    "    fam_list=fam_file.split(\"\\n\") # seperate family name from header\n",
    "    \n",
    "    family.append(fam_list[1]) # append family names to a new list\n",
    "    \n",
    "df['Families']=family # add the families names list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2d:__ Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence=[] # open new list for sequence\n",
    "\n",
    "for s in range(len(uniprot_id)):\n",
    "    seq_url=\"https://www.uniprot.org/uniprot/?query=id:\"+uniprot_id[s]+\"&columns=sequence&format=tab\" # retrieve webpage\n",
    "    seq_webpage=urllib.request.urlopen(seq_url) # open the URL\n",
    "    seq_file=seq_webpage.read().decode() # read the URL contents \n",
    "    \n",
    "    seq_list=seq_file.split(\"\\n\") # seperate sequence name from header\n",
    "    \n",
    "    sequence.append(seq_list[1]) # append sequences to a new list\n",
    "\n",
    "df['AA_Seq']=sequence # add the AA seq list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2e:__ Molecular Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecular_mass=[] # open new list for molecular mass\n",
    "\n",
    "for m in range(len(uniprot_id)):\n",
    "    mass_url=\"https://www.uniprot.org/uniprot/?query=id:\"+uniprot_id[m]+\"&columns=mass&format=tab\" # retrieve webpage\n",
    "    mass_webpage=urllib.request.urlopen(mass_url) # open the URL\n",
    "    mass_file=mass_webpage.read().decode() # read the URL contents \n",
    "    \n",
    "    mass_list=mass_file.split(\"\\n\") # seperate sequence name from header\n",
    "    \n",
    "    molecular_mass.append(mass_list[1]) # append masses to a new list\n",
    "    \n",
    "df['Molecular_Mass_(Da)']=molecular_mass # add the mass list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2f:__ Subcellular location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cell_locs=pd.read_csv(\"subcellular_locations.csv\") # open the locations list \n",
    "sub_cell_locs_list=list(sub_cell_locs.Location) # extract locations as a list\n",
    "\n",
    "subcellular_location=[] # open new list for subcellular location \n",
    "\n",
    "for l in range(len(uniprot_id)):\n",
    "    cell_url=\"https://www.uniprot.org/uniprot/?query=id:\"+uniprot_id[l]+\"&columns=comment(SUBCELLULAR%20LOCATION)&format=tab\" # retrieve webpage\n",
    "    cell_webpage=urllib.request.urlopen(cell_url) # open the URL\n",
    "    cell_file=cell_webpage.read().decode() # read the URL contents \n",
    "    \n",
    "    cell_list=cell_file.split(\"\\n\") # seperate sequence name from header\n",
    "    cell_locations1=(str(cell_list[1])).replace(\"SUBCELLULAR LOCATION: \", \"\") # turn the locations to a string \n",
    "    \n",
    "    pattern5=re.compile(r\"Note=(.*?).+\") # regular expression to remove notes found in the subcellular locations part of UniProt\n",
    "    cellular_locations2=pattern5.sub(\"\", cell_locations1) # remove notes found in the subcellular locations part of UniProt \n",
    "    \n",
    "    cellular_locations3=str([loc for loc in sub_cell_locs_list if(loc in cellular_locations2)]) # if a part of the string contains\n",
    "        # an item found in the subcellular locations list, then add to a list and turn it into a string \n",
    "    subcellular_location.append(cellular_locations3.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")) # replace punctuation in string\n",
    "\n",
    "df['Subcellular_Location']=subcellular_location # add the subcellular location list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Export the pandas dataframe to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"human_kinase_dataframe.csv\", index=False) # export pandas table to .csv and exclude indexing values as a column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
