{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhibitor csv File Generation by Web Scraping and Parsing KIDFamMap Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KIDFamMap is a database listing thousands of known kinase inhibitors. \n",
    "\n",
    "Kinases are listed on the web page at URL http://gemdock.life.nctu.edu.tw/kidfammap/browse.php and each can be clicked on individually to navigate to a page of information about that kinase. This page includes a link to another page, which contains a table of inhibitors for that kinase.\n",
    "\n",
    "Here we use the scrapy package to create and run a spider to scrape the website's HTML code for all of the relevant information.\n",
    "- First, the URLs for each kinase's web page are obtained from the main page.\n",
    "- These URLs are then followed, taking us to each kinase's web page.\n",
    "- From there we extract the URLs for the web pages containing the individual kinase's table of inhibitors\n",
    "- We then follow these URLs and extract \n",
    "    - all of the relevant information about each inhibitor\n",
    "    - the UniProt accession ID (and the kinase name for comparison)\n",
    "\n",
    "Once the data has been extracted from the website, it is cleaned and inserted into a Pandas data frame.\n",
    "\n",
    "After that, the following steps take place:\n",
    "- Using information in the data frame, we generate a column of URLs that our web app can use to display images of the inhibitors' chemical structures.\n",
    "- Convert kinases and inhibitors to uppercase.\n",
    "- Translate kinase names to match \"Entry name\" (UniProt ID) in kinase table.\n",
    "- Remove duplicate rows.\n",
    "- Remove unnecessary columns.\n",
    "- Use this data frame to make two data frames: one listing the kinase-inhibitor pairs, and one listing each inhibitor alongside all of its information. These two data sets can then be linked via the inhibitor name in our relational database.\n",
    "- Make primary key columns.\n",
    "- Export as csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the scrapy.Spider class to make your own spider\n",
    "\n",
    "class InhibitorSpider( scrapy.Spider ):\n",
    "    \n",
    "    name = \"inhibitor_spider\"\n",
    "    \n",
    "    # Define the first action to take\n",
    "        \n",
    "    def start_requests( self ): \n",
    "        \n",
    "        # Define which URL to start at\n",
    "        \n",
    "        url = 'http://gemdock.life.nctu.edu.tw/kidfammap/browse.php'\n",
    "\n",
    "        # Go to the website at the above URL and get a response object\n",
    "        # which contains the HTML code for that web page\n",
    "        # Define what to do with the response object\n",
    "        # i.e. send it to the parse method defined below\n",
    "        \n",
    "        yield scrapy.Request( url = url, callback = self.parse )\n",
    "            \n",
    "    # Using the HTML in the previous response object, get the URLs for each \n",
    "    # kinase's web page, and go to those websites\n",
    "    \n",
    "    def parse( self, response ):\n",
    "        \n",
    "        # Each kinase listed on the page is a hyperlink, leading to\n",
    "        # a page of information for that kinase\n",
    "        # Define a CSS locator to point to the hyperlinks' URLs in the HTML\n",
    "        # code and extract them as strings\n",
    "        \n",
    "        links = response.xpath( '//a/@href' ).extract()\n",
    "        #links = response.xpath( '//table/tr/td/table/tr/td/a/@href' ).extract()\n",
    "        #links = response.css( 'table > tr > td > a::attr(href)' ).extract()\n",
    "        \n",
    "        # Go to the kinases' web pages using the new URLs\n",
    "        # and send the response objects to the parse2 method below\n",
    "        \n",
    "        for link in links:\n",
    "            yield response.follow( url = link, callback = self.parse2 )\n",
    "        \n",
    "    \n",
    "    # Using the previous response objects, get the URLs for each \n",
    "    # inhibitor table\n",
    "    \n",
    "    def parse2( self, response ):\n",
    "        \n",
    "        # Each kinase's web page has a hyperlink to another page \n",
    "        # containing a table of inhibitors for that kinase\n",
    "        # Define a CSS locator to point to the URLs in those\n",
    "        # hyperlinks and extract them as strings\n",
    "        \n",
    "        inhib_links = response.xpath( '//a[@class=\"show_inhibitor\"]/@href' ).extract()\n",
    "        #inhib_links = response.css( 'a.show_inhibitor::attr(href)' ).extract()\n",
    "\n",
    "        # Go to the kinases' web pages using the new URLs\n",
    "        # and send the response objects to the parse3 method below\n",
    "        \n",
    "        for ilink in inhib_links:\n",
    "            yield response.follow( url = ilink, callback = self.parse3 )\n",
    "   \n",
    "    # Using the previous response objects, get information from the \n",
    "    # table of inhibitors for each kinase\n",
    "    \n",
    "    def parse3( self, response ):\n",
    "        \n",
    "        # Each inhibitor list web page has information we'd like to\n",
    "        # extract and place into a list \"inhibs\" (which we must initialise\n",
    "        # in the next cell rather than here)\n",
    "        # Define a CSS locator to point to the data in the rows\n",
    "        # of the inhibitor table and extract the text\n",
    "       \n",
    "        raw = response.css( 'div.result tbody > tr' ).extract()\n",
    "        uniprot = response.xpath( '//a[@target=\"_blank\"]/text()' ).extract()\n",
    "        kin = response.css( 'td.tdleft5::text' ).extract()\n",
    "        \n",
    "        # Save the data in a list \"fields\"\n",
    "        \n",
    "        fields = [ field for field in raw ]\n",
    "        \n",
    "        # For each kinase, append the information about its\n",
    "        # inhibitors to \"inhibs\"\n",
    "        \n",
    "        inhibs.append( fields )\n",
    "        kins.append( kin )\n",
    "        uniprots.append( uniprot )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the spider: crawl KIDFamMap for inhibitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kins = []\n",
    "uniprots = []\n",
    "\n",
    "# Our inhibitor table data will be returned to \"inhibs\"\n",
    "\n",
    "inhibs = [] \n",
    "\n",
    "# Run the spider\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl( InhibitorSpider )\n",
    "process.start()\n",
    "\n",
    "# N.B. kernel needs to be cleared before repeating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the data in \"inhibs\" and store in \"inhibitors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhibitors = []\n",
    "\n",
    "for i in inhibs: # for each kinase\n",
    "    for j in i: # for each kinase-inhibitor relationship\n",
    "        chemical = []\n",
    "        inh = j.split(\"</td>\") # Split row into individual fields\n",
    "        for k in inh: # for each field, remove unnecessary characters\n",
    "            field = k.replace(\"<tr>\",\"\") \n",
    "            field = field.replace(\"\\r\",\"\")\n",
    "            field = field.replace(\"\\t\",\"\")\n",
    "            field = field.replace(\"<td>\",\"\")\n",
    "            field = field.replace(\"\\n\",\"\")\n",
    "            chemical.append(field) # Make a row of cleaned, separate fields\n",
    "        inhibitors.append(chemical) # Add this row to \"inhibitors\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define column names, based on those on the KIDFamMap website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"Index\",\"Kinase\",\"Inhibitor\",\"Partial_Img_URL\",\n",
    "           \"Ki_nM\",\"IC50_nM\",\"Kd_nM\",\"EC50_nM\",\"POC\",\"Source\",\"Link\",\"To_Remove\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the inhibitors information in a Pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhibitors_df = pd.DataFrame(inhibitors, columns = headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a dictionary of kinase names with their UniProt IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinases = []\n",
    "\n",
    "for i in kins:\n",
    "    kin = str(i)\n",
    "    kin = kin.replace(\"[\",\"\")\n",
    "    kin = kin.replace(\"]\",\"\")\n",
    "    kin = kin.replace(\"\\\\r\",\"\")\n",
    "    kin = kin.replace(\"\\\\t\",\"\")\n",
    "    kin = kin.replace(\"<td>\",\"\")\n",
    "    kin = kin.replace(\"\\\\n\",\"\")\n",
    "    kin = kin.replace(\"(', ')\",\"\")\n",
    "    kin = kin.replace(\"'\",\"\")\n",
    "    kin = kin.replace(\" \",\"\")\n",
    "    kin = kin.split(\",\")\n",
    "    kinases.append(kin[0]) \n",
    "\n",
    "uniprot_ids = []\n",
    "\n",
    "for i in uniprots:\n",
    "    up = str(i)\n",
    "    up = up.replace(\"[\",\"\")\n",
    "    up = up.replace(\"]\",\"\")\n",
    "    up = up.replace(\"\\\\r\",\"\")\n",
    "    up = up.replace(\"\\\\t\",\"\")\n",
    "    up = up.replace(\"<td>\",\"\")\n",
    "    up = up.replace(\"\\\\n\",\"\")\n",
    "    up = up.replace(\"(', ')\",\"\")\n",
    "    up = up.replace(\"'\",\"\")\n",
    "    up = up.replace(\" \",\"\")\n",
    "    up = up.split(\",\")\n",
    "    uniprot_ids.append(str(up[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_dict = dict(list(zip(kinases, uniprot_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate the kinase IDs to UniProt IDs and store in column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UniProt_ID = []\n",
    "\n",
    "for n, i in enumerate( inhibitors_df.Kinase ):\n",
    "    if i in uniprot_dict.keys():\n",
    "        uni = uniprot_dict.get( i )\n",
    "        UniProt_ID.append( uni )\n",
    "    else:\n",
    "        UniProt_ID.append( float('NaN') )\n",
    "\n",
    "UniProt_ID = pd.Series( UniProt_ID )\n",
    "inhibitors_df = inhibitors_df.assign(UniProt_ID = UniProt_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using information in the data frame, generate a column of URLs for the inhibitors' chemical structure images. Our web app can subsequently use these to display images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_URL = []\n",
    "\n",
    "for n,i in enumerate(inhibitors_df.Partial_Img_URL):\n",
    "    URL = 'http://gemdock.life.nctu.edu.tw/kidfammap/data/png/'\n",
    "    URL += str(inhibitors_df.Source[n])+\"/\"\n",
    "    URL += str(i)+\".png\"\n",
    "    IMG_URL.append(URL)\n",
    "\n",
    "IMG_URL = pd.Series(IMG_URL)\n",
    "inhibitors_df = inhibitors_df.assign(IMG_URL = IMG_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make \"kinase\" and \"inhibitor\" entries uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppercase_kinase = []\n",
    "uppercase_inhib = []\n",
    "\n",
    "for n,i in enumerate(inhibitors_df.Kinase):\n",
    "    uppercase_kinase.append(str(i).upper())\n",
    "    uppercase_inhib.append(inhibitors_df.Inhibitor[n].upper())\n",
    "\n",
    "uppercase_kinase = pd.Series(uppercase_kinase)\n",
    "uppercase_inhib = pd.Series(uppercase_inhib)\n",
    "\n",
    "inhibitors_df = inhibitors_df.assign(Kinase = uppercase_kinase)\n",
    "inhibitors_df = inhibitors_df.assign(Inhibitor = uppercase_inhib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a temporary column combining the inhibitor and kinase names, to check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = []\n",
    "\n",
    "for n,i in enumerate(inhibitors_df.Inhibitor):\n",
    "    uniq = str(i)+str(inhibitors_df.Kinase[n])\n",
    "    unique.append(uniq)\n",
    "\n",
    "unique = pd.Series(unique)\n",
    "inhibitors_df = inhibitors_df.assign(UNIQUE = unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop any duplicate kinase-inhibitor pairs and reset the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhibitors_df = inhibitors_df.drop_duplicates( subset = \"UNIQUE\" )\n",
    "inhibitors_df = inhibitors_df.reset_index( drop = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop any rows without a UniProt ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhibitors_df = inhibitors_df.dropna( subset = [\"UniProt_ID\"] )\n",
    "inhibitors_df = inhibitors_df.reset_index( drop = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove any columns not required for the web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhibitors_df = inhibitors_df.drop([\"Index\", \"To_Remove\", \"Partial_Img_URL\", \"Link\", \"UNIQUE\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make data frame of kinase-inhibitor pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhib_kin_df = inhibitors_df[['Kinase', 'Inhibitor', 'UniProt_ID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make data frame of inhibitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhibitors_df = inhibitors_df.drop_duplicates(subset = \"Inhibitor\")\n",
    "inhibitors_df = inhibitors_df.drop([\"Kinase\"], axis = 1)\n",
    "inhibitors_df = inhibitors_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a column of primary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_key = []\n",
    "\n",
    "count = 1\n",
    "\n",
    "for i in inhibitors_df.Inhibitor:\n",
    "    key = \"IN\"+\"{:07d}\".format(count)\n",
    "    prim_key.append(key)\n",
    "    count += 1\n",
    "\n",
    "prim_key = pd.Series(prim_key)\n",
    "\n",
    "inhibitors_df = inhibitors_df.assign(ID_IN = prim_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_key = []\n",
    "\n",
    "count = 1\n",
    "\n",
    "for i in inhib_kin_df.Inhibitor:\n",
    "    key = \"KI\"+\"{:07d}\".format(count)\n",
    "    prim_key.append(key)\n",
    "    count += 1\n",
    "\n",
    "prim_key = pd.Series(prim_key)\n",
    "\n",
    "inhib_kin_df = inhib_kin_df.assign(ID_KI = prim_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhib_kin_df.to_csv(\"inhib_kin.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhibitors_df.to_csv(\"inhibitors.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
