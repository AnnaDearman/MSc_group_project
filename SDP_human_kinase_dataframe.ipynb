{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIO727P - Bioinformatics Software Development Group Project (2019/20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AIM: To retrive information about human protein kinases from various databases and compile into one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version: Python 2.7.16\n",
    "\n",
    "# import the required packages\n",
    "\n",
    "import pandas as pd # import pandas\n",
    "import re # import regular expression\n",
    "import urllib # import url library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1:__ Compile a list of human protein kinases using UniProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.uniprot.org/docs/pkinfam.txt\" # retrieve webpage of human kinases from UniProt\n",
    "webpage=urllib.urlopen(url) # open the URL\n",
    "myfile=webpage.read() # read the URL contents\n",
    "\n",
    "matches=re.findall(r\"([A-Z0-9]+)_HUMAN\", myfile) # create a regular expression to find all human kinases and extract all to a list\n",
    "\n",
    "human_kinases=[] # open an empty list to store UniProt identifiers for all human kinases\n",
    "\n",
    "for x in range(len(matches)):\n",
    "    human_kinases.append(matches[x]+\"_HUMAN\") # append identifiers to new list, re-adding the \"_HUMAN\" found on all identifiers\n",
    "    \n",
    "df=pd.DataFrame({'Entry_name' : human_kinases}) # create a new table with the header entry name consisting of the human_kinases list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ Extract following kinase information from UniProt:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2a:__ UniProt Accession number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_id=[]\n",
    "\n",
    "for u in range(len(human_kinases)):\n",
    "    id_url=\"https://www.uniprot.org/uniprot/?query=\"+human_kinases[u]+\"&columns=id&format=tab\" # retrieve webpage\n",
    "    id_webpage=urllib.urlopen(id_url) # open the URL\n",
    "    id_file=id_webpage.read() # read thr URL contents \n",
    "    id_list=id_file.split(\"\\n\") # seperate sequence name from header\n",
    "    uniprot_id.append(id_list[1]) # append accession numbers to an empty list\n",
    "    \n",
    "df['UniProt_ID']=uniprot_id # add the uniprot id list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2b:__ Protein names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_protein_name=[] # open two empty lists for the two different types of names we see \n",
    "alternative_protein_names=[]\n",
    "\n",
    "for x in range(len(human_kinases)):\n",
    "    protein_url=\"https://www.uniprot.org/uniprot/?query=\"+human_kinases[x]+\"&columns=protein%20names&format=tab\" # retrieve webpage\n",
    "    protein_webpage=urllib.urlopen(protein_url) # open the URL\n",
    "    protein_file=protein_webpage.read() # read thr URL contents \n",
    "    protein_list=protein_file.split(\"\\n\") # seperate protein name from header\n",
    "    pattern1=re.compile(r\"\\(EC [\\d]+\\.[\\d]+\\.[\\d]+\\.[\\d]+\\)\") # regular expression for EC numbers\n",
    "    prot_names1=pattern1.sub(\"\", (str(protein_list[1]))) # remove the EC number from the string\n",
    "    pattern2=re.compile(r\"\\(EC [\\d]+\\.[\\d]+\\.([\\d]+|\\-).\\-\\)\")\n",
    "    prot_names2=pattern2.sub(\"\", prot_names1)\n",
    "    prot_names3=prot_names2.replace(\") \", \"\").replace(\")\", \"\").replace(\"  \", \"\") # replace brackets and spaces (formatting)\n",
    "    prot_names4=prot_names3.split(\"(\") # split by open bracket\n",
    "    primary_protein_name.append(prot_names4[0]) # append the first element (the primary name)\n",
    "    prot_names4.pop(0) # remove the first element as it has already been appended\n",
    "    alternative_protein_names.append(prot_names4) # append the rest of the alternate names to another list\n",
    "\n",
    "df['Primary_Protein_Name']=primary_protein_name # add the primary names list as a column to the dataframe\n",
    "df['Alternate_Protein_Name(s)']=alternative_protein_names # add the alternate names list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2c:__ Gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primary gene symbol\n",
    "\n",
    "primary_gene_name=[]\n",
    "\n",
    "for p in range(len(human_kinases)):\n",
    "    gene_url=\"https://www.uniprot.org/uniprot/?query=\"+human_kinases[p]+\"&columns=genes(PREFERRED)&format=tab\" # retrieve webpage\n",
    "    gene_webpage=urllib.urlopen(gene_url) # open the URL\n",
    "    gene_file=gene_webpage.read() # read thr URL contents \n",
    "    gene_list=gene_file.split(\"\\n\") # seperate gene name from header\n",
    "    primary_gene_name.append(gene_list[1]) # append gene name to the new list\n",
    "\n",
    "# alternate gene symbol(s)\n",
    "\n",
    "alternative_gene_names=[]\n",
    "\n",
    "for a in range(len(human_kinases)):\n",
    "    gene_alt_url=\"https://www.uniprot.org/uniprot/?query=\"+human_kinases[a]+\"&columns=genes(ALTERNATIVE)&format=tab\" # retrieve webpage\n",
    "    gene_alt_webpage=urllib.urlopen(gene_alt_url) # open the URL\n",
    "    gene_alt_file=gene_alt_webpage.read() # read thr URL contents \n",
    "    gene_alt_list=gene_alt_file.split(\"\\n\") # seperate gene name from header\n",
    "    gene_alt_names=(str(gene_alt_list[1])).split(\" \") # split by space\n",
    "    alternative_gene_names.append(gene_alt_names) # append gene names to the new list\n",
    "\n",
    "df['Gene_Symbol']=primary_gene_name # add the primary names list as a column to the dataframe\n",
    "df['Alternative_Gene_Name(s)']=alternative_gene_names # add the alternate names list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2d:__ Families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "family=[]\n",
    "\n",
    "for f in range(len(human_kinases)):\n",
    "    fam_url=\"https://www.uniprot.org/uniprot/?query=\"+human_kinases[f]+\"&columns=families&format=tab\" # retrieve webpage\n",
    "    fam_webpage=urllib.urlopen(fam_url) # open the URL\n",
    "    fam_file=fam_webpage.read() # read thr URL contents \n",
    "    fam_list=fam_file.split(\"\\n\") # seperate family name from header\n",
    "    family.append(fam_list[1]) # append family names to a new list\n",
    "\n",
    "df['Families']=family # add the families names list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2e:__ Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence=[]\n",
    "\n",
    "for s in range(len(human_kinases)):\n",
    "    seq_url=\"https://www.uniprot.org/uniprot/?query=\"+human_kinases[s]+\"&columns=sequence&format=tab\" # retrieve webpage\n",
    "    seq_webpage=urllib.urlopen(seq_url) # open the URL\n",
    "    seq_file=seq_webpage.read() # read thr URL contents \n",
    "    seq_list=seq_file.split(\"\\n\") # seperate sequence name from header\n",
    "    sequence.append(seq_list[1]) # append sequences to a new list\n",
    "\n",
    "df['AA_Seq']=sequence # add the AA seq list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2f:__ Molecular Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecular_mass=[]\n",
    "\n",
    "for m in range(len(human_kinases)):\n",
    "    mass_url=\"https://www.uniprot.org/uniprot/?query=\"+human_kinases[m]+\"&columns=mass&format=tab\" # retrieve webpage\n",
    "    mass_webpage=urllib.urlopen(mass_url) # open the URL\n",
    "    mass_file=mass_webpage.read() # read thr URL contents \n",
    "    mass_list=mass_file.split(\"\\n\") # seperate sequence name from header\n",
    "    molecular_mass.append(mass_list[1]) # append masses to a new list\n",
    "    \n",
    "df['Molecular_Mass_(Da)']=molecular_mass # add the mass list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2g:__ Subcellular location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcellular_location=[]\n",
    "\n",
    "for l in range(len(human_kinases)):\n",
    "    cell_url=\"https://www.uniprot.org/uniprot/?query=\"+human_kinases[l]+\"&columns=comment(SUBCELLULAR%20LOCATION)&format=tab\" # retrieve webpage\n",
    "    cell_webpage=urllib.urlopen(cell_url) # open the URL\n",
    "    cell_file=cell_webpage.read() # read thr URL contents \n",
    "    cell_list=cell_file.split(\"\\n\") # seperate sequence name from header\n",
    "    cell_locations=str(cell_list[1]) # turn the locations to a string \n",
    "    pattern3=re.compile(r\"[A-Za-z0-9]+:[A-Za-z0-9]+\\|[A-Za-z0-9]+:[A-Za-z0-9]+(\\}|\\,)\") # regex to remove pubmed IDs etc\n",
    "    cellular_locations1=pattern3.sub(\"\", cell_locations) # replace with nothing\n",
    "    pattern4=re.compile(r\"Note=([A-Za-z0-9].+)\") # regex to remove notes \n",
    "    cellular_locations2=pattern4.sub(\"\", cellular_locations1) # replace with nothing\n",
    "    pattern5=re.compile(r\"{[A-Za-z0-9]+:[A-Za-z0-9]+\") # regex to remove other IDs \n",
    "    cellular_locations3=pattern5.sub(\"\", cellular_locations2) # replace with nothing\n",
    "    cellular_locations4=cellular_locations3.replace(\" {.\", \",\").replace(\" {;\", \",\").replace(\" }.\", \",\").replace(\" }\", \",\").replace(\" ;\", \"\"). replace(\" { .\", \",\").replace(\";\", \"\").replace(\"SUBCELLULAR LOCATION: \", \"\").replace(\".\", \",\")\n",
    "        # replace all punctuation with nothing OR commas\n",
    "    if len(cellular_locations4)==0:\n",
    "        cellular_locations4+=\"NA\" # if field is empty, add NA\n",
    "    cellular_locations4+=\".\" # add full stop to end of all fields, for the sake of formatting in excel later on\n",
    "    subcellular_location.append(cellular_locations4) # append string of locations to empty list\n",
    "    \n",
    "df['Subcellular_Location']=subcellular_location # add the subcellular location list as a column to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Export the pandas dataframe to a .csv type file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"human_kinase_dataframe.csv\", index=False) # export pandas table to .csv and exclude indexing values as a column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
