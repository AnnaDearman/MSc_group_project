{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping KIDFamMap 1 of 2:\n",
    "## Scraping kinase IDs and making a list of URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KIDFamMap is a database listing thousands of known kinase inhibitors. \n",
    "\n",
    "340 kinases are listed on the \"browse\" page at URL http://gemdock.life.nctu.edu.tw/kidfammap/browse.php.\n",
    "\n",
    "Each kinase acts as a hyperlink that can be clicked on to navigate to a \"kinase\" page, containing information about that kinase.\n",
    "\n",
    "The \"kinase\" page includes a link to an \"inhibitors\" page, containing a list of inhibitors for either\n",
    "- the same kinase, or\n",
    "- a \"reference kinase\"\n",
    "\n",
    "This means that a simple spider that performs the following:\n",
    "- scrape and follow every \"kinase\" page URL from the \"browse\" page\n",
    "- scrape and follow every \"inhibitor\" page URL from the \"kinase\" page\n",
    "- scrape and parse the inhibitor details from the \"inhibitor\" page\n",
    "\n",
    "would not return the inhibitor details for all 340 kinases, because the kinases that link to \"reference kinases\", rather than themselves, would be skipped.\n",
    "\n",
    "However, it is possible to manually insert the kinase ID of interest into any \"inhibitors\" page's URL, in order to find its inhibitor information. Some kinases simply do not have any inhibitors listed on KIDFamMap, but many more do.\n",
    "\n",
    "Here we use the scrapy package to make a spider to scrape all of the 340 kinase IDs on KIDFamMap. We then generate the 340 \"inhibitor\" page URLs using a loop. These URLs will be used in \"Web-scraping-KIDFamMap_2-of-2_Inhibitor-information-and-csv-generation.ipynb\" to scrape KIDFamMap for the inhibitor details and produce two tables for our database: \"inhib_kin.csv\" and \"inhibitors.csv\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the scrapy.Spider class to make a kinase-name-scraping spider\n",
    "\n",
    "class KinaseSpider( scrapy.Spider ):\n",
    "    \n",
    "    name = \"kinase_spider\"\n",
    "    \n",
    "    # Define the first action to take\n",
    "        \n",
    "    def start_requests( self ): \n",
    "        \n",
    "        # Define which URL to follow\n",
    "        \n",
    "        url = 'http://gemdock.life.nctu.edu.tw/kidfammap/browse.php'\n",
    "\n",
    "        # Go to the website at the above URL and get a response object\n",
    "        # which contains the HTML code for that web page\n",
    "        # Define what to do with the response object\n",
    "        # i.e. send it to the parse method defined below\n",
    "        \n",
    "        yield scrapy.Request( url = url, callback = self.parse )\n",
    "            \n",
    "    # Using the HTML in the previous response object, get the kinase \n",
    "    # names\n",
    "    \n",
    "    def parse( self, response ):\n",
    "        \n",
    "        # Define an xpath locator to point to the kinases in the HTML\n",
    "        # code and extract them as strings\n",
    "        # place into a list \"kinases\" (which we must initialise in the\n",
    "        # next cell rather than here)\n",
    "        \n",
    "        kins = response.xpath( '//td/a/text()' ).extract()\n",
    "        \n",
    "        kinases.append( kins )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the spider: crawl KIDFamMap for kinases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinases = []\n",
    "\n",
    "# Run the spider\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl( KinaseSpider )\n",
    "process.start()\n",
    "\n",
    "# N.B. kernel needs to be cleared before repeating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kinases are all stored in the first element of the \"kinases\" list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinases = kinases[ 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make URLs from the kinases list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinase_urls = []\n",
    "\n",
    "for i in kinases:\n",
    "    url = \"http://gemdock.life.nctu.edu.tw/kidfammap/show_inhibitor.php?QueryType=Protein&QueryName=\" + str( i ) + \"&Query_Pid=\" + str( i )\n",
    "    kinase_urls.append( url )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( kinase_urls )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
